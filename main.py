import sys
import os
import re
import time
import json
import configparser
import requests
import importlib.util
import chardet
import subprocess
from pathlib import Path
from typing import Tuple, Dict
from datetime import datetime, timezone 

# --- å¸¸é‡ ---
CACHE_FILE = Path("cache.json")
CONFIG_FILE = Path("config.ini")
REQUIRED_LIBRARIES = ["requests", "chardet", "configparser"]

# --- å®ç”¨åŠŸèƒ½ï¼šç¯å¢ƒæ£€æŸ¥ä¸ç¼–ç æ£€æµ‹ ---

def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åº“"""
    missing = [lib for lib in REQUIRED_LIBRARIES if not importlib.util.find_spec(lib)]
    
    if missing:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing)}")
        for pkg in missing:
            print(f"æ­£åœ¨å®‰è£… {pkg}...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", pkg], 
                                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                print(f"âœ… {pkg} å®‰è£…æˆåŠŸ")
            except Exception:
                print(f"âŒ æ— æ³•å®‰è£… {pkg}ã€‚è¯·æ‰‹åŠ¨å®‰è£…:")
                print(f"   {sys.executable} -m pip install {pkg}")
                sys.exit(1)

def detect_file_encoding(file_path: Path) -> str:
    """æ£€æµ‹æ–‡ä»¶ç¼–ç """
    try:
        with file_path.open("rb") as f:
            result = chardet.detect(f.read(1024))
            if result["encoding"] and result["confidence"] > 0.5:
                return result["encoding"]
    except Exception:
        pass
    return "iso-8859-1"

# --- é…ç½®åŠ è½½ (æ•´åˆæ‰€æœ‰é…ç½®) ---

def load_config_settings(config_file: Path) -> dict:
    """ä» config.ini ä¸­åŠ è½½æ‰€æœ‰é…ç½®ï¼ŒåŒ…æ‹¬ API Key å’Œé€šç”¨è®¾ç½®ã€‚"""
    config = configparser.ConfigParser()
    if not config_file.exists():
        raise EnvironmentError(f"é…ç½®æ–‡ä»¶ {config_file} æœªæ‰¾åˆ°ã€‚è¯·æ ¹æ® config.ini.sample åˆ›å»ºã€‚")

    config.read(config_file, encoding='utf-8')
    
    settings = {}
    try:
        # DeepL Section
        settings['api_key'] = config.get("deepl", "api_key").strip()
        settings['translate_url'] = config.get("deepl", "translate_url").strip()
        settings['usage_url'] = config.get("deepl", "usage_url").strip()
        
        # Settings Section
        settings['sleep_time'] = config.getfloat("settings", "sleep_time")
        settings['quota_threshold'] = config.getfloat("settings", "quota_threshold")
        settings['max_batch_chars'] = config.getint("settings", "max_batch_chars")

        if not settings['api_key']:
             raise EnvironmentError(f"é…ç½®æ–‡ä»¶ {config_file} ä¸­ [deepl] éƒ¨åˆ†çš„ api_key ä¸èƒ½ä¸ºç©ºã€‚")

    except configparser.Error as e:
        raise EnvironmentError(f"é…ç½®æ–‡ä»¶ {config_file} è¯»å–é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„é…ç½®é¡¹ã€‚è¯·å‚è€ƒ config.ini.sampleã€‚è¯¦ç»†é”™è¯¯: {e}")
    except ValueError as e:
        raise EnvironmentError(f"é…ç½®æ–‡ä»¶ {config_file} ä¸­é…ç½®å€¼ç±»å‹é”™è¯¯ï¼ˆå¦‚ sleep_time æˆ– quota_threshold åº”ä¸ºæ•°å­—ï¼‰ï¼š{e}")
    
    return settings

# --- DeepL API äº¤äº’ ---

class DeepLAPI:
    """DeepL API äº¤äº’ç±»"""
    def __init__(self, api_key: str, settings: dict):
        self.api_key = api_key
        self.settings = settings

    def _handle_error(self, response: requests.Response, endpoint_name: str):
        """é€šç”¨é”™è¯¯å¤„ç†ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ 403 é”™è¯¯ç«‹å³é€€å‡ºã€‚"""
        if response.status_code == 403:
            print(f"\nğŸ”´ DeepL API è‡´å‘½é”™è¯¯ (403 Forbidden) åœ¨ {endpoint_name} è¯·æ±‚ä¸­ã€‚")
            print("åŸå› é€šå¸¸æ˜¯ API Key æ— æ•ˆã€æ ¼å¼é”™è¯¯ï¼ˆä¾‹å¦‚è¢«å¼•å·åŒ…è£¹ï¼‰æˆ–å·²è¢«åŠé”€ã€‚")
            print(f"è¯·æ£€æŸ¥ config.ini ä¸­ [deepl] -> api_key çš„å€¼ã€‚")
            print(f"DeepL é”™è¯¯å“åº”: {response.text[:150]}...")
            sys.exit(1)
        
        response.raise_for_status()


    def translate(self, text: str) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        if not text.strip():
            return ""

        data = {
            "auth_key": self.api_key,
            "text": text,
            "target_lang": "ZH"
        }

        try:
            response = requests.post(self.settings['translate_url'], data=data, timeout=10)
            self._handle_error(response, "ç¿»è¯‘")
            translated = response.json()["translations"][0]["text"]
            time.sleep(self.settings['sleep_time'])
            return translated
        except requests.exceptions.RequestException as e:
            print(f"\nâŒ ç¿»è¯‘è¯·æ±‚å¤±è´¥: {e}")
            return ""


    def get_usage(self) -> Tuple[int, int, float, str]:
        """è·å– API ä½¿ç”¨é‡ä¿¡æ¯ (ç”¨äºé…é¢æ£€æŸ¥)"""
        response = requests.get(self.settings['usage_url'], params={"auth_key": self.api_key}, timeout=5)
        self._handle_error(response, "ç”¨é‡æŸ¥è¯¢")
        
        data = response.json()
        used = data.get("character_count", 0)
        limit = data.get("character_limit", 500000)
        percentage = (used / limit) if limit else 0
        
        # --- æå–å¹¶æ ¼å¼åŒ–é‡ç½®æ—¥æœŸ ---
        # å°è¯•è·å– period_end_time (æ–°å­—æ®µ) æˆ– end_time (æ—§å­—æ®µ/Proå­—æ®µ)
        end_time_data = data.get("period_end_time") or data.get("end_time") 
        
        reset_date_str = "æœªçŸ¥"
        if end_time_data:
            try:
                if isinstance(end_time_data, (int, float)):
                    # æ—¶é—´æˆ³æ ¼å¼ï¼ˆç§’ï¼‰
                    dt_obj = datetime.fromtimestamp(end_time_data, tz=timezone.utc)
                elif isinstance(end_time_data, str):
                    # ISO 8601 å­—ç¬¦ä¸²æ ¼å¼ (e.g., "2025-05-13T09:18:42Z")
                    dt_obj = datetime.fromisoformat(end_time_data.replace('Z', '+00:00'))
                else:
                    raise ValueError("Unsupported date format.")
                
                reset_date_str = dt_obj.strftime("%Y-%m-%d %H:%M:%S UTC")
            except (TypeError, ValueError, AttributeError):
                # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ™ä¿æŒ "æœªçŸ¥"
                pass
            
        return used, limit, percentage, reset_date_str
            
# --- ç¼“å­˜ç®¡ç† ---

class TranslationCache:
    """ç¿»è¯‘ç¼“å­˜ç®¡ç†ç±»"""
    def __init__(self):
        self.cache: Dict[str, str] = self._load_cache()

    def _load_cache(self) -> Dict[str, str]:
        if CACHE_FILE.exists():
            try:
                with CACHE_FILE.open("r", encoding="utf-8") as f:
                    return json.load(f)
            except json.JSONDecodeError:
                return {}
        return {}

    def save(self):
        with CACHE_FILE.open("w", encoding="utf-8") as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)

    def get(self, text: str) -> str | None:
        return self.cache.get(text)

    def set(self, text: str, translation: str):
        self.cache[text] = translation
        self.save()

# --- SRT æ–‡ä»¶å¤„ç† ---

def process_srt_file(file_path: Path, api: DeepLAPI, cache: TranslationCache, settings: dict):
    """å¤„ç†å•ä¸ªSRTæ–‡ä»¶ï¼Œé‡‡ç”¨æ‰¹é‡ï¼ˆChunk-Basedï¼‰ç¿»è¯‘"""
    print(f"\nğŸ¬ æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path.name}")
    
    SPLIT_TOKEN = "<DEEPL_SPLIT_TOKEN>" 
    MAX_CHARS = settings.get('max_batch_chars', 45000)
    
    try:
        encoding = detect_file_encoding(file_path)
        content = file_path.read_text(encoding=encoding)
        
        blocks = re.split(r"(\d+\n\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}\n)", content.strip()) 
        blocks = blocks[1:]
        
        indexed_blocks = [blocks[i] + blocks[i+1] for i in range(0, len(blocks), 2)]
        total = len(indexed_blocks)
        
        batches = []
        current_batch_text = ""
        current_batch_indices = []
        
        all_translations = {} 

        for idx, block in enumerate(indexed_blocks):
            lines = block.split("\n")
            if len(lines) < 2:
                continue

            index, timestamp, *text_lines = lines
            english_text = re.sub(r"\[.*?\]|\{.*?\}", "", " ".join(text_lines)).strip()
            
            cached_translation = cache.get(english_text)
            if cached_translation is not None:
                all_translations[english_text] = cached_translation
                continue
            
            text_to_add = english_text + SPLIT_TOKEN
            
            if len(current_batch_text) + len(text_to_add) > MAX_CHARS and current_batch_text:
                batches.append((current_batch_text, current_batch_indices))
                current_batch_text = ""
                current_batch_indices = []
            
            current_batch_text += text_to_add
            current_batch_indices.append(english_text)

        if current_batch_text:
            batches.append((current_batch_text, current_batch_indices))

        
        print(f"ğŸ“¦ ç¿»è¯‘æ‰¹æ¬¡æ€»æ•°: {len(batches)}")
        
        for batch_idx, (batch_text, original_texts) in enumerate(batches):
            sys.stdout.write(f"\râš™ï¸ æ­£åœ¨ç¿»è¯‘æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)}...")
            sys.stdout.flush()

            translated_batch_text = api.translate(batch_text)

            if translated_batch_text:
                translated_segments = translated_batch_text.split(SPLIT_TOKEN)
                
                for i, original_text in enumerate(original_texts):
                    if i < len(translated_segments) and translated_segments[i].strip():
                        translation = translated_segments[i].strip()
                        all_translations[original_text] = translation
                        cache.set(original_text, translation)
            
            else:
                print(f"\nâŒ æ‰¹æ¬¡ {batch_idx + 1} ç¿»è¯‘å¤±è´¥æˆ–è¿”å›ç©ºç»“æœã€‚")

        new_blocks = []
        for idx, block in enumerate(indexed_blocks):
            lines = block.split("\n")
            if len(lines) < 2:
                new_blocks.append(block)
                continue

            index, timestamp, *text_lines = lines
            english_text = re.sub(r"\[.*?\]|\{.*?\}", "", " ".join(text_lines)).strip()
            
            translated = all_translations.get(english_text)
            
            if not translated:
                translated = cache.get(english_text) or "ã€ç¿»è¯‘å¤±è´¥æˆ–åŸæ–‡ä¸ºç©ºã€‘"

            original_lines = [l for l in text_lines if l.strip()]
            new_block = [index, timestamp, *original_lines, translated]
            new_blocks.append("\n".join(new_block))
            
            progress_bar = f"[{'#' * int((idx + 1) / total * 20):20}]"
            sys.stdout.write(f"\râœ… è¿›åº¦: {progress_bar} {((idx + 1) / total)*100:.1f}% ({idx + 1}/{total})")
            sys.stdout.flush()


        output_file = file_path.with_suffix(".zh.srt")
        output_file.write_text("\n\n".join(new_blocks) + "\n\n", encoding="utf-8")
        print(f"\nğŸ‰ ç¿»è¯‘å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file.name}")

    except Exception as e:
        print(f"\nâŒ å¤„ç† {file_path.name} å¤±è´¥: {e}")

# --- ä¸»å‡½æ•° ---
def main():
    print("âœ¨ SRT æ‰¹é‡ç¿»è¯‘å·¥å…· âœ¨")
    
    # 1. ç¯å¢ƒæ£€æŸ¥
    try:
        check_and_install_dependencies()
        settings = load_config_settings(CONFIG_FILE)
    except Exception as e:
        print(f"ğŸ”´ å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
        
    # 2. åˆå§‹åŒ– API å’Œæ£€æŸ¥é…é¢
    try:
        api = DeepLAPI(settings['api_key'], settings)
        
        used, limit, percentage, reset_date_str = api.get_usage()
        
        quota_threshold = settings['quota_threshold']
        
        # --- ä¼˜åŒ–è¾“å‡ºé€»è¾‘ ---
        
        if reset_date_str == "æœªçŸ¥":
            # å…è´¹å¥—é¤ä¸æä¾›é‡ç½®æ—¥æœŸï¼Œæä¾›æ¸…æ™°æç¤º
            reset_output = "DeepL API å…è´¹å¥—é¤ä¸æä¾›ç¡®åˆ‡é‡ç½®æ—¥æœŸã€‚è¯·ç™»å½• DeepL è´¦æˆ·é—¨æˆ·æŸ¥çœ‹ã€‚"
        else:
            reset_output = f"é…é¢é‡ç½®æ—¥æœŸ: {reset_date_str}."

        usage_info = f"   å·²ä½¿ç”¨å­—ç¬¦æ•°: {used:,} / é™åˆ¶: {limit:,} ({percentage*100:.2f}%)."
        
        if percentage > quota_threshold:
            print(f"\nğŸ”´ DeepL API é…é¢å³å°†è€—å°½ï¼")
            print(usage_info)
            print(f"   {reset_output}")
            print("ç¨‹åºå·²é€€å‡ºã€‚")
            sys.exit(1)
        elif percentage > quota_threshold - 0.15: 
            print(f"\nâš ï¸ DeepL API é…é¢ä½¿ç”¨è­¦å‘Šï¼")
            print(usage_info)
            print(f"   {reset_output}")
        else:
             print(f"\nğŸŸ¢ DeepL API é…é¢æ£€æŸ¥é€šè¿‡ã€‚")
             print(usage_info)
             print(f"   {reset_output}")

    except requests.exceptions.RequestException as e:
        # æ•è·æ‰€æœ‰åœ¨åˆå§‹åŒ– API æˆ–æ£€æŸ¥ç”¨é‡æ—¶å‘ç”Ÿçš„ç½‘ç»œ/HTTP é”™è¯¯
        print(f"\nğŸ”´ å¯åŠ¨å¤±è´¥ï¼šæ— æ³•è¿æ¥ DeepL API æˆ–æœåŠ¡å™¨è¿”å›é”™è¯¯ã€‚")
        print(f"   è¯¦ç»†é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥ã€DeepL API Key æ˜¯å¦æœ‰æ•ˆï¼Œä»¥åŠ API ç«¯ç‚¹æ˜¯å¦æ­£ç¡®ã€‚")
        sys.exit(1)
    except EnvironmentError as e:
        print(f"ğŸ”´ DeepL é…ç½®é”™è¯¯: {e}")
        sys.exit(1)
        
    # 3. æŸ¥æ‰¾æ–‡ä»¶å¹¶å¤„ç†
    cache = TranslationCache()
    srt_files = [f for f in Path.cwd().glob("*.srt") if not f.name.endswith(".zh.srt")]

    if not srt_files:
        print("\nâš ï¸ åœ¨å½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ°å¾…ç¿»è¯‘çš„ SRT æ–‡ä»¶ (*.srtï¼Œè·³è¿‡ *.zh.srt)ã€‚")
        print("è¯·å°† SRT æ–‡ä»¶æ”¾å…¥ç¨‹åºæ‰€åœ¨ç›®å½•åé‡è¯•ã€‚")
        return

    print(f"æ‰¾åˆ° {len(srt_files)} ä¸ª SRT æ–‡ä»¶ï¼Œå¼€å§‹ç¿»è¯‘...")
    
    for file in srt_files:
        process_srt_file(file, api, cache, settings)

    print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ã€‚")

if __name__ == "__main__":
    main()
